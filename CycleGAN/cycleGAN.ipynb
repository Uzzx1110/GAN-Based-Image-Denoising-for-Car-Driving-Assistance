{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from glob import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 clean images extracted successfully in trainB!\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "source_dir = r\"C:\\Users\\uzmap\\Documents\\GitHub\\CarDrivingAssistance\\dataset\\IDD_Segmentation\\leftImg8bit\\train\"\n",
    "output_dir = \"dataset/CycleGANShorter/trainB\"  # Target directory for clean images\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Extract images from all numbered folders (limit to 1500)\n",
    "folders = sorted(os.listdir(source_dir))\n",
    "image_count = 0\n",
    "max_images = 1500\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(source_dir, folder)\n",
    "    images = glob(f\"{folder_path}/*.png\")  # Adjust extension if needed\n",
    "    \n",
    "    for img in images:\n",
    "        if image_count >= max_images:\n",
    "            break  # Stop if we reach 1500 images\n",
    "        \n",
    "        shutil.copy(img, os.path.join(output_dir, os.path.basename(img)))\n",
    "        image_count += 1\n",
    "\n",
    "    if image_count >= max_images:\n",
    "        break  # Stop processing further folders if the limit is reached\n",
    "\n",
    "print(f\"{image_count} clean images extracted successfully in trainB!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All noisy images moved to trainA with unique names!\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "source_dirs = {\n",
    "    \"FOG\": r\"C:\\Users\\uzmap\\Documents\\GitHub\\CarDrivingAssistance\\dataset\\IDDAW\\train\\FOG\\rgb\",\n",
    "    \"RAIN\": r\"C:\\Users\\uzmap\\Documents\\GitHub\\CarDrivingAssistance\\dataset\\IDDAW\\train\\RAIN\\rgb\",\n",
    "    \"LOWLIGHT\": r\"C:\\Users\\uzmap\\Documents\\GitHub\\CarDrivingAssistance\\dataset\\IDDAW\\train\\LOWLIGHT\\rgb\",\n",
    "    \"SNOW\": r\"C:\\Users\\uzmap\\Documents\\GitHub\\CarDrivingAssistance\\dataset\\IDDAW\\train\\SNOW\\rgb\",\n",
    "}\n",
    "\n",
    "output_dir = \"dataset/CycleGANShorter/trainA\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Move all images with unique names\n",
    "for category, src in source_dirs.items():\n",
    "    images = glob(f\"{src}/**/*.png\", recursive=True)  # Adjust extension if needed\n",
    "    for img in images:\n",
    "        base_name = os.path.basename(img)  # Original filename\n",
    "        new_name = f\"{category}_{base_name}\"  # Prefix with folder name\n",
    "        shutil.copy(img, os.path.join(output_dir, new_name))\n",
    "\n",
    "print(\"All noisy images moved to trainA with unique names!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FOG: 175 ‚Üí 375 (Adding 200)\n",
      "Processing LOWLIGHT: 78 ‚Üí 375 (Adding 297)\n",
      "Processing RAIN: 152 ‚Üí 375 (Adding 223)\n",
      "Processing SNOW: 167 ‚Üí 375 (Adding 208)\n",
      "`trainA_balanced` now has exactly 1500 images (375 per class).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "# Base paths\n",
    "base_path = r\"D:\\CarDrivingAssistance\\dataset\\CycleGANShorter\\trainA\"  # All images\n",
    "output_path = r\"D:\\CarDrivingAssistance\\dataset\\CycleGANShorter\\trainA_balanced\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Target images per class\n",
    "target_per_class = 375 \n",
    "\n",
    "# Categories\n",
    "categories = [\"FOG\", \"LOWLIGHT\", \"RAIN\", \"SNOW\"]\n",
    "\n",
    "# Function to apply safe augmentations\n",
    "def augment_image(img):\n",
    "    \"\"\"Apply random but safe augmentations for road scene data.\"\"\"\n",
    "    \n",
    "    # Random horizontal flip\n",
    "    if random.random() > 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "\n",
    "    # Random brightness/contrast\n",
    "    alpha = random.uniform(0.7, 1.3)  \n",
    "    beta = random.randint(-40, 40)  \n",
    "    img = np.clip(alpha * img + beta, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Get all images in trainA\n",
    "all_images = glob(f\"{base_path}/*.png\")\n",
    "\n",
    "# Group images by their category using filename prefixes\n",
    "category_images = {cat: [] for cat in categories}\n",
    "for img_path in all_images:\n",
    "    filename = os.path.basename(img_path)\n",
    "    for cat in categories:\n",
    "        if filename.startswith(cat):  # Check prefix\n",
    "            category_images[cat].append(img_path)\n",
    "\n",
    "# Balance dataset by copying originals first, then augmenting if needed\n",
    "for category, images in category_images.items():\n",
    "    num_existing = len(images)\n",
    "    num_needed = max(0, target_per_class - num_existing)\n",
    "\n",
    "    print(f\"Processing {category}: {num_existing} ‚Üí {target_per_class} (Adding {num_needed})\")\n",
    "\n",
    "    # Copy original images first\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        new_name = os.path.basename(img_path)  # Keep original filename\n",
    "        cv2.imwrite(os.path.join(output_path, new_name), img)  # Save original\n",
    "\n",
    "    # Generate augmented images if needed\n",
    "    for i in range(num_needed):\n",
    "        img_path = random.choice(images)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = augment_image(img)\n",
    "        \n",
    "        # Save augmented images with unique names\n",
    "        new_name = f\"{category}_aug_{i}_{os.path.basename(img_path)}\"\n",
    "        cv2.imwrite(os.path.join(output_path, new_name), img)\n",
    "\n",
    "print(f\"`trainA_balanced` now has exactly {target_per_class * len(categories)} images (375 per class).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 300 images from D:\\CarDrivingAssistance\\dataset\\CycleGANShorter\\trainA_balanced ‚Üí D:\\CarDrivingAssistance\\dataset\\CycleGANShorter\\testA\n",
      "Moved 299 images from D:\\CarDrivingAssistance\\dataset\\CycleGANShorter\\trainB ‚Üí D:\\CarDrivingAssistance\\dataset\\CycleGANShorter\\testB\n",
      "Dataset split completed!\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"D:\\CarDrivingAssistance\\dataset\\CycleGANShorter\"\n",
    "trainA_dir = os.path.join(data_dir, \"trainA_balanced\")  # Rename it later to trainA\n",
    "trainB_dir = os.path.join(data_dir, \"trainB\")\n",
    "testA_dir = os.path.join(data_dir, \"testA\")\n",
    "testB_dir = os.path.join(data_dir, \"testB\")\n",
    "\n",
    "# Create test folders\n",
    "os.makedirs(testA_dir, exist_ok=True)\n",
    "os.makedirs(testB_dir, exist_ok=True)\n",
    "\n",
    "# Define test split percentage\n",
    "test_ratio = 0.2  # 20% for testing\n",
    "\n",
    "def split_data(train_dir, test_dir, test_ratio):\n",
    "    \"\"\"Move a percentage of images from train to test.\"\"\"\n",
    "    images = glob(f\"{train_dir}/*.png\")  # Adjust extension if needed\n",
    "    test_size = int(len(images) * test_ratio)\n",
    "\n",
    "    test_images = random.sample(images, test_size)\n",
    "\n",
    "    for img in test_images:\n",
    "        shutil.move(img, os.path.join(test_dir, os.path.basename(img)))\n",
    "\n",
    "    print(f\"Moved {test_size} images from {train_dir} ‚Üí {test_dir}\")\n",
    "\n",
    "# Split trainA ‚Üí testA and trainB ‚Üí testB\n",
    "split_data(trainA_dir, testA_dir, test_ratio)\n",
    "split_data(trainB_dir, testB_dir, test_ratio)\n",
    "\n",
    "print(\"Dataset split completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking images in D:/CarDrivingAssistance/dataset/CycleGANShorter/trainA_balanced...\n",
      "üîç Checking images in D:/CarDrivingAssistance/dataset/CycleGANShorter/trainB...\n",
      "üîç Checking images in D:/CarDrivingAssistance/dataset/CycleGANShorter/testA...\n",
      "üîç Checking images in D:/CarDrivingAssistance/dataset/CycleGANShorter/testB...\n",
      "\n",
      "Corrupt images detected:\n",
      "\n",
      "Total corrupt images found: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Dataset directories to scan\n",
    "dataset_dirs = [\n",
    "    \"D:/CarDrivingAssistance/dataset/CycleGANShorter/trainA_balanced\",\n",
    "    \"D:/CarDrivingAssistance/dataset/CycleGANShorter/trainB\",\n",
    "    \"D:/CarDrivingAssistance/dataset/CycleGANShorter/testA\",\n",
    "    \"D:/CarDrivingAssistance/dataset/CycleGANShorter/testB\"\n",
    "]\n",
    "\n",
    "corrupt_files = []\n",
    "\n",
    "# Function to check corrupt images\n",
    "def find_corrupt_images(folder):\n",
    "    global corrupt_files\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Skipping missing folder: {folder}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üîç Checking images in {folder}...\")\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                img.load()  # Force loading the image fully\n",
    "        except (OSError, IOError):\n",
    "            print(f\"Corrupt image detected: {file_path}\")\n",
    "            corrupt_files.append(file_path)\n",
    "\n",
    "# Scan all dataset folders\n",
    "for folder in dataset_dirs:\n",
    "    find_corrupt_images(folder)\n",
    "\n",
    "# Print corrupt file names\n",
    "print(\"\\nCorrupt images detected:\")\n",
    "for file in corrupt_files:\n",
    "    print(file)\n",
    "\n",
    "print(f\"\\nTotal corrupt images found: {len(corrupt_files)}\")\n",
    "\n",
    "#D:\\CarDrivingAssistance\\dataset\\trainB\\007949_leftImg8bit.png was found corrupted and was deleted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonPractice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
